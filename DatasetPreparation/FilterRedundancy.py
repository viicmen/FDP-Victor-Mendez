#
# FUNCTIONS TO FILTER THE REDUNDANCY IN THE DATASET
#

import numpy as np
from sklearn.cluster import AgglomerativeClustering
import subprocess

def FilterAligment(aligment, output_file):
'''
The input is the output from a All vs All MMseqs2 alingment.
Processes the output of an all-vs-all MMseqs2 alignment. 
For each query sequence, it keeps hits with more than 70% identity and that have not been previously seen. 
It groups similar sequences into clusters and writes each cluster to a line in the output file.
'''

    with open(aligment, 'r') as f:

        dic = {}   
        seen = set()

        hit = f.readline()
        hit = hit.split()
        query = hit[0]
        target = hit[1]
        idp = float(hit[2])
        dic[query] = dic.get(query, []) + [target]

        prev = query

        for hit in f.readlines():

            hit = hit.split()
            query = hit[0]
            target = hit[1]
            idp = float(hit[2])

            if idp > 0.7 and target not in seen:

                dic[query] = dic.get(query, []) + [target]
                seen.add(target)

            if prev != query:
                seen.add(prev)
                prev = query

    with open(output_file, 'w') as out_file:
        for _ in dic.values():
            out_file.write(' '.join(_) + '\n')

    return


def BuildMatrix():
'''
Reads Tomtom motif comparison results and builds a symmetric adjacency matrix of -log(p-value) * 1000 between motif pairs. 
The matrix is used for clustering based on similarity.
'''
    dic={}
    with open('./tomtom_out/tomtom.tsv', 'r') as tomtom_output:
        tomtom_output.readline()
        line = tomtom_output.readline()
        while line != '\n':

            line = line.split()
            query = line[0]
            target = line[1]
            pvalue = line[5]

            if query not in dic:
                dic[query] = [(target, pvalue)]
            else:
                dic[query] += [(target, pvalue)]

            line = tomtom_output.readline()
    order = list(dic.keys())
    len_order = len(order)
    adj_matrix = []
    for query in dic:
        r = ['' for i in range(len_order)]
        for pair in dic[query]:
            target, pvalue = pair
            i = 0
            while target != order[i]:
                i += 1
            r[i] = round(float(pvalue)*1000,3)
        adj_matrix.append(r)

    adj_matrix = np.array(adj_matrix)
    adj_matrix = (adj_matrix+adj_matrix.T)/2
    np.fill_diagonal(adj_matrix,0)
    return adj_matrix


def GetLongestMotif(pwms_path, pwms, labels):
'''
Given a list of motif names and their cluster labels.
Returns the longest motif from each cluster by comparing the number of lines in each corresponding MEME file.
'''
    for c in set(labels):

        longest_m = ''
        max_l = 0

        for i, m in enumerate(pwms):

            if c == labels[i]:

                with open(pwms_path+m+'.meme','r') as motif:

                   num_l = sum(1 for _ in motif)
                   if num_l > max_l:
                       longest_m = m
                       max_l = num_l

        return longest_m



def FilterMotifs(input_file, output_file, pwms_dir):
'''
The input is the file generated by FilterAligment.
Filters motifs for downstream use. For each cluster of motifs, it performs Tomtom comparisons to assess similarity. 
Based on the number of motifs and similarity, it selects either individual or the longest representative motif and writes it to the output file. 
Uses hierarchical clustering if more than two motifs are present.
'''
    with open(input_file, 'r') as f, open(output_file, 'w') as out_file:

        for line in f.readlines():
            
            line = line.split()

            if len(line) == 1:

                subprocess.run(['grep', '-A', '1', line[0], output_file], stdout=out_file)

            elif len(line) == 2:

                subprocess.run(['tomtom', pwms_dir + line[0] + '.meme', pwms_dir + line[1] + '.meme', '-thres', '1'])
                with open('tomtom_out/tomtom.tsv', 'r') as t:
                    t.readline()
                    qvalue = float(t.readline().split()[5])
                if qvalue > 0.001:
                    subprocess.run(['grep', '-A', '1', line[0], output_file], stdout=out_file)
                    subprocess.run(['grep', '-A', '1', line[1], output_file], stdout=out_file)
                else:
                    subprocess.run(['grep', '-A', '1', line[0], output_file], stdout=out_file)
            else:
                
                with open('memes', 'w') as memes_file:
                    for pwm in line:
                        with open(pwms_dir + pwm + '.meme', 'r') as pwm_file:
                            memes_file.write(pwm_file.read())

                subprocess.run(['tomtom', 'memes', 'memes', '-thres', '1'])
                adj_matrix = build_matrix()
                cluster = AgglomerativeClustering(n_clusters=None, metric="precomputed", linkage="single", distance_threshold=1)
                labels = cluster.fit_predict(adj_matrix)
                longest = get_longest_motif(pwms_dir, line, labels)
                subprocess.run(['grep', '-A', '1', longest, output_file], stdout=out_file)
                
